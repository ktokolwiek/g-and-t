{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out images using embeddings a.k.a. G&T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukaszkopec/.pyenv/versions/3.7.0/envs/mturk-backend/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from gandt.data import analyse_labels_data\n",
    "from gandt.data.filter_data import filter_by_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather files with annotations\n",
    "You would get them from S3, like so:\n",
    "\n",
    "```\n",
    "aws s3 sync s3://your-bucket/20200219-all-multicategory/labelled/20200219-multicategory-user-relabel .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can list all the json files from Ground Truth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_files = glob.glob(\n",
    "        '../data/external/labelled/2020010*/annotations/'\n",
    "        'consolidated-annotation/consolidation-request/iteration-1/*.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_responses = pd.concat([analyse_labels_data.read_responses(x)\n",
    "                           for x in experiment_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty responses - not sure how they got there!\n",
    "empty_removed = raw_responses[True & (raw_responses['labels'].apply(len))]\n",
    "\n",
    "# Sometimes there are duplicates in label files, so get rid of them,\n",
    "# only accept the first response per worker per image\n",
    "raw_responses = empty_removed.groupby(\n",
    "    ['worker_id', 'image_filename', 'image_index'],\n",
    "    as_index=False).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter responses by unreliable workers\n",
    "\n",
    "This will add 'is_label_certain' column, which we can use to filter out\n",
    "unreliable labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a60df5217a4053ae40911796a2307c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unfiltered_responses, filtered_responses = (\n",
    "    analyse_labels_data.filter_out_unreliable_workers(raw_responses))\n",
    "filtered_responses['source'] = 'prints'\n",
    "\n",
    "# Take only images for which we are certain of the label/ s\n",
    "labelled_data = filtered_responses[filtered_responses['is_label_certain']]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge with image filenames on disk, so that we can evaluate the feature\n",
    "extraction model on them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = pd.DataFrame({'full_path': [\n",
    "    os.path.abspath(x) for x in\n",
    "    (glob.glob('../data/external/print-data-resized/*/*') +\n",
    "     glob.glob('../../utility.flickr-data-download/data/external/'\n",
    "               'event_types/2019-07-18/images/*')\n",
    "     )\n",
    "]})\n",
    "\n",
    "images['image_filename'] = images['full_path'].apply(os.path.basename)\n",
    "\n",
    "labelled_data = labelled_data.merge(\n",
    "    images, on='image_filename', how='inner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = tf.keras.applications.ResNet152V2(\n",
    "    include_top=True, weights='imagenet')\n",
    "\n",
    "# Get a feature extraction layer from the model\n",
    "\n",
    "feat_extractor = tf.keras.Model(\n",
    "    inputs=embedding_model.input,\n",
    "    outputs=embedding_model.get_layer(\"avg_pool\").output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get filenames of images to be labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_print_images = pd.DataFrame(\n",
    "    {'full_path': [\n",
    "        os.path.abspath(x) for x in\n",
    "        glob.glob('../data/external/print-data-resized/*/*')]\n",
    "    })\n",
    "unknown_print_images = unknown_print_images[\n",
    "    ~unknown_print_images['full_path'].isin(labelled_data['full_path'])]\n",
    "unknown_print_images['majority_label'] = 'Unknown'\n",
    "\n",
    "unknown_print_images = unknown_print_images.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the filtering!\n",
    "\n",
    "This evaluates the images using the feature extraction model, and then filters\n",
    "images which are far away from all labelled categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3198 validated image filenames.\n",
      "  1/100 [..............................] - ETA: 12:14"
     ]
    }
   ],
   "source": [
    "discarded, remaining = filter_by_similarity(\n",
    "    feat_extractor, labelled_data, unknown_print_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}